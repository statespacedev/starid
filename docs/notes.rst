notes
============

drafts
--------

summer of ninety - the university of texas at austin astronomy department - in recent months the hubble space telescope had finally reached orbit, and the berlin wall had fallen - rent was less than two hundred a month, just a short walk north of campus - martha ann zively, the eighty-three year old landlady, lived directly overhead, and mobile phones, notebook computers, and the web were all somewhere over the horizon - home internet was a dialup modem into the universities access point. since the previous fall, work meant the hubble space telescope astrometry team - a group with members from the astronomy department, mcdonald observatory, the aerospace engineering department, the center for space research, and the european space agency and its hipparcos project - paul hemenway, an astronomer involved with all those organizations, was both mentor and friend. hubble was designed for very exact and stable pointing to minimize motion smear in its images - three optical interferometers were mounted on robotic arms in the hubble’s focal plane to provide feedback to the pointing control system - these fine guidance sensors were a cutting-edge solution given seventies and eighties technology, with its uneasy mix of the analog and digital eras. exact calibrations were needed on-orbit to make the whole complex system work as intended.

asteroids were the calibration targets - mcdonald observatory and csr efforts for hubble fgs calibration became a component of the texas minor planet project. with group members in the astronomy and aerospace departments, asteroid orbit determinations were refined to the point where predicted positions and motions were exact enough to use as ground-truth references for comparison with hubble observations. primary tools were a dec vax/vms cluster at csr, the main astronomy department vax running bsd unix, various early sun workstations, and the eighty-two inch telescope at mcdonald. it could image asteroids onto glass photographic plates, given enough time - a data general nova minicomputer and the suitcase sized cassegrain camera were used for the long exposures needed to gather enough light from these dim objects. this was another complex piece of custom-made analog hardware - for locking on to and tracking a guide star, it used an image dissector, a large photomultiplier tube attached to the camera’s side that looked a bit like an oversized oil-filter. its circular field of view was divided into four quadrants - a guide star was manually positioned at the center and the closed-loop control system was activated - every second, with a loud mechanical knock, the system would bodily adjust the camera position and try to keep the guide star at the center - meanwhile, on a green phosphorescent screen, a fuzzy spot bounced about, now nearer the center of the cross hairs, now further out.

an observing night began a few hours before sunset. down in the telescope control room, circling the building beneath the telescope floor, the minicomputer and its control programs had to be started - outside on the catwalk at the base of the dome was a spectacular view of the shadows growing out across the high desert from the mountains - various obsolete computers and mysterious bits of hardware crowded the corners of the control room - the curving walls, low ceiling, red leds, and glowing crt terminals completed the brooding sci-fi ambience. a stack of white envelopes, each containing a glass photographic plate, waited on a desk - to prepare, a control room terminal with a command line program on the nova generated telescope pointing information for a list of asteroids. using this mini was probably the last serious contact with the large eight-inch floppy disks - they were a vanishing breed by the late 80s. after jotting down notes for the planned observations, the plates were moved up into the dome, where it was pitch black except for clouds of stars in the open slit - the telescope loomed overhead in the darkness.

caution was required climbing up the stairs onto the circular telescope floor - it rose and descended in order to stay near the camera as the telescope moved - one could easily step off in the dark, high above the dome floor. the massive base of the telescope and attached camera hung at eye level - sliding out the plate holder cover opened a rectangular frame of stars, with the silhouette of the telescope secondary mirror housing and its support struts high above. mcdonald maintenance staff had mounted the camera and connected power cables, but fine tuning was always needed, and the telescope itself had to be focused - this meant adjusting the position of the secondary mirror. a rocker switch on the telescope hand controller activated a motor to move the secondary inward or outward - the exact determination of focus was old-school, using a knife-edge. in the telescope’s focal plane, all of the light from a star converges through a single point. when a knife-edge cuts through that point, the light from the star is cut off instantly - if the knife-edge dims the star gradually, then the secondary mirror position needs to be adjusted. the point of instant cut off needed to be where the photographic plates were held by the camera, so a special metal frame mounting a straight knife-edge was fastened into the plate holder, for adjusting the secondary mirror position while watching the knife-edge. if there was a bit of spare time, the metal frame could be replaced with another special frame holding the eyepiece, a glass lens heavy enough to require both hands to lift - peering inside, one saw directly a mysterious world of red or green nebulas or spiraling galaxies...

once the telescope was ready, camera configuration came next. with the small field of view of the telescope - effectively a high magnification - asteroids moved significantly, relative to the background stars, over an interval of around ten minutes - each asteroid was a bit different, and various orbital characteristics had to be taken into account - the direction and rate of relative motion had already been computed by the nova - now the camera body was rotated in its mounting, relative to the telescope, and programmed to move at the apparent rate of the target asteroid, so it would appear to be motionless. the rear-surface of the image dissector was a round crt screen divided into four quadrants. light from a star, cascading down through the photomultiplier tube, formed a green glow on the screen. a guide-star was found near the asteroid and centered on the screen - with the tracking loop activated, the camera position was updated once per second with a mechanical click, keeping the star at the center of the screen. an asteroid exposure usually began with guide-star tracking - then the steady clicking of the control loop would go silent for a period, and the sky would turn while asteroid-light built up a darker spot on the photograph plate - then the clicking would resume. the result was a dumbbell shape for stars, with two circular peaks connected by a trail - the asteroid was a trail with a circular peak at its midpoint. these peaks and trails became visible the next day when the plates were developed. each plate had many dumbbell shaped stellar trails - short or long, thick or thin - and at the center of the plate, a single ufo shaped asteroid-image.

reducing the glass plates to digital data and improving knowledge of the asteroid orbits followed over the next days and weeks - this all took place back in austin, where the center for space research and department of aerospace engineering became involved - their expertise in orbit determination played an important role in the hubble astrometry team - the space age was roughly thirty years old, and members of its first generation led the center for space research - ray duncombe, byron tapley, and bob schutz. first, the plates had to be measured using a scanner and minicomputer in the scanning room, hidden behind the astronomy department library on the thirteenth floor of robert lee moore hall - better known simply as rlm. many hours passed in the scanning room - it was a meditative kind of place, cool and dark, with a steady loud drone from electronics fans. the long back wall was covered with cabinets containing thousands of glass plates, including historic sets of survey plates from palomar and the european southern observatory, alongside many plates from mcdonald - black plastic sheets shielded the end of the room from stray light, and at the center of this cave sat the pds microdensitometer. this was a machine for mechanically scanning photographs - an interesting time capsule of analog-era technology. light from a bulb was focused into a beam downward through a mechanically driven stage with position encoders. a photometer below the stage measured the transmitted intensity while the stage moved in a raster pattern. sampling of the photometer and encoders was done by a very early, mini-fridge sized, rack-mounted sun workstation.

may or june of ninety was the first observing run at mcdonald - chat among the astronomers was about serious problems with hubble that were repeatedly making headline news - there was still lots of discussion of the high gain antennas, because news of the catastrophic error in the primary-mirror hadn’t yet leaked out - overhearing the veterans during those days at mcdonald was an early revelation about the realities of science and technology. it was an eight-hour drive to west texas from austin - three or four nights were occupied with making plates with the eighty-two inch - then came the drive back to austin. texas summer heat was just beginning to get intense, and after a sweltering walk over to rlm it was nice to settle into the cool darkness of the scanning room - that little apartment could be uncomfortably warm during the day, even with the air conditioning running full blast.

the plates were roughly the size and shape of writing paper - the glass was fairly thin and fragile - held up against a background light, the star and asteroid trails were small dark smudges. with the plate secured to the pds scanning stage, and looking across the plate’s surface, dull black trails of photographic emulsion were obvious on the surface of the glass, and the control software on the workstation had to be told which trails to scan. this meant moving the scanning beam about the plate, manually steering the stage and noting coordinates - at the top of the pds, roughly at eye level, was a circular glass screen showing a magnified image of the plate illuminated by the scanning beam - individual grains of photographic emulsion were visible, and when the beam was near a star trail it appeared as a fuzzy black worm. the stage was adjusted using two finely geared knobs, and the coordinates of the scanning beam were shown by two sets of red leds on the pds console - the corners of a rectangle about a star trail were the coordinates for a raster scan, and were entered in manually at the workstation keyboard.

the workstation was a tall rack standing in the back corner and mounting a mini-fridge sized early sun box - on a table beside the rack was an extremely heavy old crt monitor showing one of the first primitive unix graphical user interfaces, the sunview precursor to x windows - this machine already had the antiquated feel of an earlier era. a scanning session meant creating a set of digitized raster files, one file for each trail scanned by the pds, archived on 9-track half-inch tape - a group of files, say thirty to fifty for a plate with a good exposure and lots of stars, was created in the filesystem of the workstation and then written to tape using its sibling above on the sixteenth floor, which had the tape drive - the shift over the border from analog to digital took place in the seventies style electronics connecting the pds to the workstation. a few days after scanning those first plates - paul and ray duncombe discussed the next steps in wrw, the aerospace building. there's a clear memory of the short walk from rlm to wrw - stopping in the texas sun - overhead was the typical hard blue summer sky with little white clouds, and sweat running down just seconds after stepping outside the air conditioning - the thunderbolt question has struck from a clear sky - exactly which stars were on those plates? how could those stars really, in practice, be determined, in order to determine the position of the asteroid? was there a program on the astronomy or aerospace computers to do that? the answer was, no - there wasn’t an easy or obvious solution, and helping to figure out a practical method of identifying those stars on those particular plates was the real job - not that an undergrad had any chance of even beginning to find a real solution, but even beginning to be aware of and recognize the magnitude of the problem was a huge step forward - how did one go about recognizing stars - humans could do it, but could an eighties computer system?

thirteen years later, the boss for the next eleven years was bob schutz - working in aerospace and the icesat group at the center for space research, mostly on star trackers - modern descendents of maritime sextants for celestial navigation - along with inertial sensors, often referred to simply as gyros. the problems once again, at root, concerned images containing a scattering of unknown stars - within aerospace, it’s a classic problem with a memorable name - the lost in space problem. given an image of some stars, exactly which stars are they? aerospace has its own perspectives, culture, and tools - astronomers don’t generally think in terms of three-dimensional unit vectors, rotation matrices, quaternions, and vector-matrix notation - it was very quickly apparent that the concerns and methods in aerospace were more widely applicable than those in astronomy - bringing together optimization, control, data fusion, high performance computing, and nn to solve practical real-world problems. within weeks of beginning, star identification was again one of the top concerns - and once again the first question was whether a practical solution was already available. pete shelus from the hubble astrometry days was a member of the group and pointed out useful directions - there was a strong sense of continuity and awareness that here was a problem that really needed addressing - the obvious differences now were that computing hardware was more powerful, and digital imaging had become standard - there was no longer an analog to digital divide to cross - everything was already in binary.

icesat’s control system usually made it straightforward to predict which stars each image contained - this wasn’t obvious or straightforward at first and it took effort and thought to really understand the data coming from the spacecraft - there were four star imagers of three different hardware-types onboard, all sampling at ten hertz or more - these were classic eighties star trackers and didn't provide star identifications. there was also higher-frequency angular-rate data from the inertial unit, and tracking data from the control system - so a pointing vector could usually be estimated for each star-image, and it was usually enough to check whether star-images with appropriate brightnesses were near their predicted positions. brightness information tends to muddy the star identification problem because it’s relatively difficult to measure and predict for a particular imager - images have better geometric information than brightness information - an astronomer interested in brightness does photometry with dedicated sensors, not with imagers. an additional check was that angles between observed star pairs matched predictions, and one of the first objectives was to model errors in these angles from flight data - focusing on star pairs is a big step in the direction of looking at star triangles and patterns.

it turned out there's a fascinating, though relatively small, literature on star identification and related topics - by the second world war, many large aircraft had a bubble window facing upward for a navigator to make stellar observations - after the war, computing and imaging automated the process. the cold war brought new motivations for the technology - many people became uneasily aware of guidance systems, and while most of the massive efforts went into integrated circuits and inertial guidance sensors, automated star tracking quietly matured in parallel. star trackers are critical for spacecraft, and are used on high altitude aircraft and missiles - the classical period was the sixties through the eighties. surprisingly though, it soon became clear that there was still no publicly-available software package for the lost-in-space star identification problem - apparently, each time star identification software had been developed, it’s been within classified or industry projects. if you were seriously interested in star identification, you probably wanted to sell star trackers - that’s a fairly mature industry now.

another thirteen years passed - excitement was growing again, after the ai winter following the eighties, around advances in neural networks - especially at google, which had just open sourced tensorflow. for a number of reasons, it was clearly time to tackle the problem directly, using both geometric and nn methods in parallel where possible - the concept was to start from scratch as a github open source project, integrating tensorflow from the beginning. this meant working in c++ eigen and python numpy - the only external input was to be a list of star positions, and nasa’s skymap star catalog was an ideal source. skymap was created in the 90s specifically for use with star trackers - we’d used it extensively for icesat, even collaborating where possible with its creators. when hubble was launched, one of its early problems was bad guide stars. as part of the overall hubble recovery effort, nasa pushed skymap forward as an improved description of the sky, as seen by standard star trackers.

skymap is simply a list of star positions, so how does one generate a star image? the core problem is searching for neighbors of an arbitrary point on a sphere - for example, given a list of points on earth, which of the points are near a particular latitude and longitude? the usual answers involve dividing the sphere up into tiles, transforming and subdividing, etc - even a square-sky is not unheard of. a more dynamic and flexible approach was published by daniele mortari - it’s closely related to lookup and hash tables, but has some unique and interesting quirks - it starts off by viewing stars as unit vectors with three coordinates between plus-one and minus-one. we’re searching for stars within small ranges of each coordinate - picture three thin rings on the sky, one centering on each coordinate-axis, and finding the stars inside the small region where the rings intersect. we’re left with three independent searches for small ranges of values, followed by an intersection of the results - each search is performed on a separate precomputed key-value table, with sorted keys from plus-one to minus-one, and values representing star labels - performance can be improved by fitting a curve to the sorted floating-point keys, then using it to calculate the bounding lower and upper indexes into the table, creating something like a ranged-search hash-table with the fitted curve acting as a hash function.

cultural differences between nn and aerospace became apparent - to oversimplify, nn wants to be about two dimensional images, while aerospace wants to be about physical three dimensional unit vectors. a higher-level image interface organically grew over the lower-level unit vector geometry over a period of a few months, and a curious sequence of coincidences took place - standard nineties star tracker images were eight degrees by eight degrees - 28,000 arcseconds per side - roughly sixteen times the apparent diameter of the moon. the hello world problem in nn, mnist, was standardized in the late nineties using data files and images with 28 pixels per side. adapting those standards resulted in star images with thousand-arcsecond pixels - at first, actual mnist data files were simply overwritten with star images, then fed into standard nn processors - gradually, additional advantages became apparent, beyond data file format compatibility - the implications are deeper than nice rounding properties, since they effectively mean low resolution - at the level of a toy camera or blurry mobile phone photo - by comparison, real star tracker images can involve sub-arcsecond resolutions. low resolution makes the star identification problem more challenging and interesting - it forces use of global structures and patterns within an image, rather than localized features and heuristics - there’s simply less information available and more has to be done with less. it even suggests questions about how the human brain solves the problem and identifies stars - for example, a typical high-resolution aerospace algorithm might focus on the exact distance between a pair of stars, along with the angle to a third star - that’s clearly not how the brain works, so what's the brain in fact doing?

focusing on low resolution, mnist-like images led to a discovery - to identify a particular star in an image, it's helpful to shift the star to the image-center and make its presence implicit - there’s no point in including it in the image, what’s significant is the relative-geometry of the other stars. the target star becomes the origin of the coordinate system, and if there’s another star nearby, as often happens in a low resolution image, there’s no confusion - in practice, the effects are even nicer, since, in a way, there's a 'free' extra star and less need for coordinate transformations. all the way back to ninety, it was clear that the shapes of triangles formed by a star field can be used to identify the stars - and that iterative and even recursive processes could be involved - but once you start thinking about triangles, they tend to multiply, which seems uncomfortable - where does it end? skipping ahead to the answer, enlightenment arrives with a simple restatement of the lost-in-space problem - start with a set of candidate star identities and iteratively set aside those that can’t be correct until only one remains - it’s brute force, and deeper insights are likely possible - the main thing is, it works.

between the star-level and triangle-level is the pair-level - in practice, it’s the fundamental structural unit, and soon after code for star images came code for pairs separated by less than eleven degrees on the sky. this was the fourth use of the key-value table described above, to represent nearly one million pairs as angles and member star identifiers. the initial concept was to focus on groups of four stars instead of just three - for a triangle of three stars, adding a fourth provides significantly more information - six edges instead of three, two of which are a shared pair - the tradeoff is significantly more complexity. for two adjacent triangles, the shared-pair represents a new type of constraint for which stars are possible - picture two sets of possible stars for the two triangles, kept in agreement via the shared-pair. with low resolution, this is harder than it sounds - there are too many pairs that meet low resolution constraints - a low resolution shared-pair just doesn’t provide enough unique information, it’s too ambiguous - in other words, at low resolution many of the skies triangles are similar. eventually, the concept of the shared-pair became the focus - any pair of stars can be a shared-pair parent with many child-triangles. with the target star implicit in the center of an image containing ten other stars, there are ten shared-pairs that include the target star - each of these is the parent of nine child-triangles.
